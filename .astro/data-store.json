[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.12.3","content-config-digest","9a97ecde9b2695a7","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://umai-tech.com\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[[null,{\"logger\":{\"options\":{\"dest\":{},\"level\":\"info\"},\"label\":\"astro-mermaid\"}}]],\"rehypePlugins\":[[null,{\"logger\":{\"options\":{\"dest\":{},\"level\":\"info\"},\"label\":\"astro-mermaid\"}}]],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"rawEnvValues\":false},\"legacy\":{\"collections\":false}}","blog",["Map",11,12,29,30,45,46],"unpopular-opinion-hard-good-ds",{"id":11,"data":13,"body":24,"filePath":25,"digest":26,"legacyId":27,"deferredRender":28},{"title":14,"description":15,"pubDate":16,"updatedDate":17,"tags":18,"author":23},"Unpopular Opinion - It's harder than ever to be a good data scientist","It is an understatement to say that AI, particularly the Data Science profession, is changing drastically with the introduction of GenAI and Large Language Models. In today's GenAI-driven world, being a good data scientist is more challenging than ever.",["Date","2024-10-20T00:00:00.000Z"],["Date","2024-10-25T00:00:00.000Z"],[19,20,21,22],"Data Science","Large Language Models","AI Engineering","Career Advice","Marcus Elwin","import Callout from '@components/Callout.astro';\n\nOver the past **6+ years** (and nearly a **decade** being involved with AI), I've worked across various industries and companies of all sizes, from large corporations üè¢ to agile startups üöÄ. This experience has given me a front-row seat üéüÔ∏è to the diverse structures and maturity levels of data science teams and their adjacent roles. Like many data professionals, I recently transitioned to *AI engineering* ü§ñ, focusing on the practical deployment of GenAI and Large Language Models (LLMs) in production environments over the past year.\n\nThe data science landscape has evolved rapidly üåê, especially with the rise of GenAI and LLMs. While these advancements have opened new doors üö™, they have also made it more challenging than ever to be a **\"good\"** data scientist. From managing high expectations in organizations with little to no data strategy üèóÔ∏è to navigating the hype that has turned everyone into self-proclaimed \"AI specialists\" üßë‚Äçüíª, the role of a data scientist is more complex than it once was.\n\nIn this article, I'll share my thoughts and experiences on the challenges data scientists face today. We'll look at what it means to be a **V-shaped data scientist** üìä, how data quality issues impact performance ‚ö†Ô∏è, the importance of deep domain knowledge üß†, and the blurred lines between *DataOps, MLOps, AIOps*, and traditional *DevOps* üîÑ. My goal is to shed light on the realities of this profession and why the path to becoming a genuinely skilled data scientist is more demanding than ever.\n\n\u003CCallout type=\"info\" title=\"Disclaimer\">\nThe quotes may or may not be inspired by real people. All images are AI generated.\n\u003C/Callout>\n\n## What is a good Data Scientist?\n\n> So you say you want to do Deep Learning, we don't do any learning here. Rather unlearning. So, focus on Data Engineering instead.  \n> ‚Äî **Random Employer in 2015**\n\nWhen I began my career in data science, my work primarily involved using **R** and **SQL** to conduct statistical analysis for the stock exchange, focusing on trading behavior. The cutting-edge computer vision and deep learning algorithms I had studied felt distant from my day-to-day reality at the time. However, as my career progressed, I had the opportunity to apply deep learning techniques and deploy them in real-world production environments. This evolution mirrors a broader shift in the expectations placed on data scientists, which have expanded from traditional machine learning to deep learning and now GenAI and Large Language Models (LLMs).\n\nThe role of a \"good\" data scientist has continuously evolved, and so have the titles and responsibilities. Depending on the company or industry, a data scientist might focus on anything from statistical modeling to full-stack AI deployment. (*See more on this under Issue #3*). Despite these variations, there are core skills that are essential for data scientists to thrive in today's dynamic industry.\n\nThis brings us to the concept of the \"V-shaped Data Scientist.\"\n\n```mermaid\ngraph TD;\n A[Data Scientist]\n B[Logical Thinking, Mathematical & Statistical Fundamentals]\n C[Domain and Business Understanding]\n D[System Design and Architecture Skills]\n E[Ownership of End-to-End Application Stack]\n F[Intellectual Curiosity and Continuous Learning]\n\n A -->|Core Skills| B\n A -->|Differentiators in AI application| C\n A -->|Crucial for AI Systems| D\n A -->|Beyond Proficiency in Modeling| E\n A -->|Essential for Keeping Up-to-Date| F\n\n B -->|Critical for| G[Verifying AI-Generated Content]\n C -->|Leads to| H[Solving Actual User-Centric Use Cases]\n D -->|Includes| I[Monitoring, Tracing, Drift Detection]\n E -->|Reduces Need For| J[Building Custom Models]\n F -->|Enables| K[Adaptation to Rapid Industry Changes]\n\n G -.->|In context of| J\n I -.->|Supports| E\n K -.->|Necessitates| C\n H -->|Benefits from| D\n```\n\nAs I see it, there are five key areas where a successful data scientist must be versatile:\n\n1. **Logical Thinking, Mathematical & Statistical Fundamentals**: A solid understanding of these principles is the foundation for building reliable models and verifying outputs.\n\n2. **Domain and Business Understanding**: Knowing the industry context ensures that data solutions address real-world problems and create value.\n\n3. **System Design and Architecture Skills**: Building scalable and maintainable systems requires a grasp of system architecture, especially for deploying AI models.\n\n4. **Ownership of End-to-End Application Stack**: From data preprocessing to model deployment, owning the entire workflow allows for seamless integration and maintenance.\n\n5. **Intellectual Curiosity and Continuous Learning**: The rapidly changing field demands a passion for continuous learning to stay current with emerging trends and technologies.\n\nThese skills form the core of a \"V-shaped\" data scientist who combines depth in specific areas with broad capabilities across the entire data or ML workflow.\n\n```mermaid\npie title Skills of a V-shaped Data Scientist\n \"Deep Expertise in AI & ML\": 30\n \"Programming & System Development\": 20\n \"Data Engineering\": 20\n \"Business Acumen\": 20\n \"Ethics & Governance\": 10\n```\n\nFor more on the concept of the V-shaped data scientist, check out my detailed article in [V-shaped Data Scientist in the Era of Generative AI](https://medium.com/gopenai/v-shaped-data-scientist-in-the-era-of-generative-ai-b29f1bca93b7).\n\n## Issue #1 - High expectations but no data or data strategy\n\n> We need to do AI, especially GenAI and LLMs. Our competitors are ahead of us with this AI thing. ChatGPT right? Make a chatbot. Make something cool. And by the way, we have no data available for the first year you work here. Privacy issues. GDPR.\n> ‚Äî **Random Manager in 2023**\n\n![Fig 1. High expectations without any clear strategy, makes it hard for AI as well](/images/blog/unpopular-opinion-hard-good-ds/pic_issue_1.png)\n\n*Fig 1. High expectations without any clear strategy, makes it hard for AI as well. Source: Author.*\n\nAI is now on every board and company wish list. Since the inception of ChatGPT in late 2022, there's been a rush to become \"AI-driven,\" with many businesses eager to integrate AI capabilities into their products. Implementing AI using Large Language Models (LLMs) may seem more effortless than ever, but the reality is far more complex.\n\nAs a data scientist working to bring ML systems or LLMs into production, I've encountered several vital challenges that reveal a gap between expectations and reality. Regardless of whether we call it AI, ML, or LLM, the success of these technologies hinges on having a solid foundation in place.\n\nHere are some of the main issues:\n\n**No Data** üèóÔ∏è:\n* *The Data Pipeline Dilemma*: Even the most advanced AI models are useless without data. Many companies need to pay more attention to the importance of having robust data pipelines that can collect, clean, and prepare data for analysis. As a data scientist, you may spend more time convincing the organization to invest in data engineers or analytics engineers who can help build these essential pipelines.\n  \n* *Scattered and Unstructured Data:* Companies may also have data, but it is often siloed, inconsistent, or poorly structured, making it difficult to use effectively for AI applications.\n  \n**No Data Strategy** üß≠:\n* *Data Without Direction*: Simply having data is not enough. You might face significant roadblocks without a clear strategy for leveraging this data. For example, sensitive data that cannot be used freely or a lack of data governance can lead to major compliance and privacy issues. Data science efforts might lack meaningful insights or business value without a strategic approach.\n  \n* *Becoming Truly Data-Driven:* A proper data strategy means clearly understanding what data is needed, how it will be collected, and how it can drive the company's goals. Without this, data scientists solve problems that don't matter or create solutions that no one will use.\n\n**No AI Strategy** üéØ:\n* *\"We Need AI, But We Don't Know Why\"*: This is a common scenario. Many companies feel pressured to adopt AI simply because it's the latest trend, without understanding how it fits into their business model. Implementing AI without a clear use case is like building a solution in search of a problem. For example, creating a fancy Text2SQL bot or chatbot might sound great, but without a clear vertical or objective, it's unlikely to yield significant benefits.\n  \n* *Defining Real-World Use Cases*: An effective AI strategy should map out specific business problems where AI can offer a competitive advantage. Without this focus, data science projects can become expensive experiments that don't deliver ROI.\n\n**No Labeling Strategy üè∑Ô∏è**:\n* *The Need for Accurate Evaluation*: Although LLMs are remarkably capable, you still need to evaluate their outputs, which often require labeled data. While relying on the \"LLM as a judge\" approach is tempting, this can lead to misleading conclusions if the model isn't properly benchmarked.\n  \n* *Ownership and Management of Labels*: Labeling data is critical to many AI workflows, especially for tasks requiring supervised learning. This means someone needs to take ownership of the labeling process, ensuring quality, consistency, and relevance. Without a clear labeling strategy, data scientists are left trying to generate signals from data they don't fully understand, leading to a confusing and ineffective model development cycle.\n  \n* *Synthetic Data vs. Real Labels*: There's been growing interest in using generated or synthetic data to fill gaps, and while this can be helpful, it's not a cure-all. Creating or generating data without understanding the underlying patterns might reinforce biases or miss critical insights, leading to flawed models.\n\n\u003CCallout type=\"warning\" title=\"The Reality Check\">\nThese challenges highlight a common theme: **high expectations but a lack of foundational support**. Companies eager to adopt AI must first address these fundamental issues by investing in data infrastructure, developing clear strategies, and fostering a culture that understands the importance of quality data. Otherwise, the gap between expectations and reality will widen, making it harder for data scientists to deliver meaningful results.\n\u003C/Callout>\n\nI think this is also a key reason why many Data Scientists quit and progress to do something else e.g., Data Engineering. *Luckily*, more and more companies are starting to understand this and employ a **CAIO or Chief AI Officer**.\n\n## Issue #2 - AI, GenAI, and LLM hype everyone is now \"AI\" specialists\n\n> AI, AI for real came in 2022 right with ChatGPT; I have done 5 courses in Prompt Engineering, which is not that hard, right? It works when I try on my oversimplified, non-realistic version of reality on my local machine, which does not consider scale or cost. So chop, chop, make it work. \n> ‚Äî **Random Manager / non AI Co-worker in 2024**\n\n![Fig 2. There are too many false AI prophets these days](/images/blog/unpopular-opinion-hard-good-ds/pic_issue_2.png)\n\n*Fig 2. There are too many false AI prophets these days. Source: Author.*\n\nSince the launch of Large Language models like GPT, the AI landscape has experienced an explosion of interest, driving businesses to position themselves as \"AI-driven\" almost overnight. While the increased attention to AI has sparked innovation, it has also led to misconceptions and unrealistic expectations. Many organizations quickly jump on the AI bandwagon without truly understanding what it means to implement these technologies effectively.\n\nHere are some key challenges this hype has created:\n\n**The Rise of the Self-Proclaimed \"AI Specialist\" üßë‚Äçüíª**:\n* *Overnight Experts*: The commoditization of AI, primarily through LLMs, has made these powerful tools much more accessible. With platforms like [Cursor](https://www.cursor.com/) simplifying coding tasks, it has become easier for anyone to claim technical expertise. This has led to a surge of people rebranding themselves as \"AI specialists\" after taking a short course in \"Prompt Engineering\" or reading a few blogs. However, knowing how to ask ChatGPT relevant questions doesn't make someone an expert in any domain. This overconfidence and influx of self-proclaimed experts can dilute the quality of AI projects, leading to a false sense of competence that ultimately hampers real progress.\n\n**Over-Reliance on Plug-and-Play AI Solutions üîå**:\nAs many of you have undoubtedly noticed, AI‚Äîparticularly Generative AI (GenAI)‚Äîhas become increasingly commoditized. This means that AI can now be integrated into existing systems as a module or component, making it more accessible and widespread. While this democratization is a positive step for increasing AI adoption, it has also led to a surge in so-called **\"OpenAI or GPT wrappers\"**‚Äîapplications that add a basic layer over pre-existing models, like ChatGPT, without offering significant value beyond the core functionalities.\n\nAnyone can build a simple Retrieval-Augmented Generation (RAG) solution, but not everyone can build one that scales effectively. This over-reliance on plug-and-play solutions presents several key challenges:\n\n* **The Illusion of Simplicity**: Plug-and-play tools can create a false sense of ease. Businesses might believe they can integrate AI quickly without understanding the complexities of deployment, scaling, or maintenance.\n\n* **Limited Customization and Differentiation**: Many of these solutions are quick to set up but offer little customization. Companies often end up with generic AI tools that don't differentiate them from competitors.\n\n* **Scalability and Performance Challenges**: While it's easy to prototype with a plug-and-play model, scaling that solution to real-world use cases can be different. Performance bottlenecks, cost inefficiencies, and data integration issues can arise.\n\n**Thinking that LLMs are a universal tool or a panacea for everything ML-related** üè•:\n**Large Language Models (LLMs)** are potent tools‚Äîthey excel at generating text, answering questions, and extracting information from unstructured data. However, they are not a one-size-fits-all solution for every machine learning problem. AI has been evolving since the 1950s, and various algorithms have been developed, each suited to specific tasks.\n\n**Use LLMs Where They Shine**: LLMs are great for tasks like generating coherent text, summarizing content, language translation, and even providing conversational interfaces.\n\n**But Don't Overreach**: Despite their capabilities, LLMs are not well-suited for every problem. For instance, regression tasks, time series forecasting, and clustering are areas where traditional machine learning models often perform better.\n\n\u003CCallout type=\"success\" title=\"Key Takeaway\">\nSo, in short, next time you want to use an LLM for something ML already does better: **Trust your Data Scientist's or ML Engineers' judgment** üß†; this is what they are trained for!\n\u003C/Callout>\n\n## Issue #3: The Inconsistent Nature of Data Science Roles Across Companies\n\n> Data Scientist? What do you do? I mean, for real? Can't you help me with this dashboard and a SQL query to get my ad-hoc nonreusable insights that I will probably forget I asked about?\n> ‚Äî **Random Co-worker in 2024**\n\n![Fig 3. Unfortunate that you don't have as many arms as responsibilities](/images/blog/unpopular-opinion-hard-good-ds/pic_issue_3.png)\n\n*Fig 3. Unfortunate that you don't have as many arms as responsibilities. Source: Author.*\n\nData Scientist was once hailed as the sexiest job of the 21st century, but now AI Engineer seems to be taking that spot. However, even before this shift, it was often unclear what a Data Scientist was actually supposed to do. The responsibilities of a Data Scientist can vary widely depending on the company, industry, and even the team they're a part of. This inconsistency has led to confusion for both employers and professionals trying to build their careers.\n\n**Different Interpretations of the Role**:\n\n* **Product Analyst**: In some companies, Data Scientists function mainly as product analysts, focusing on tasks like A/B testing, user behavior analysis, and generating business insights.\n\n* **Data Engineer**: At other companies, the role may lean heavily towards data engineering‚Äîbuilding and maintaining data pipelines, integrating various data sources, and ensuring data quality.\n\n* **Machine Learning Engineer**: Conversely, some companies expect their Data Scientists to act as ML Engineers, handling the end-to-end lifecycle of machine learning models.\n\n**Broadened Skill Requirements**: The role of Data Scientist has continued to evolve, and nowadays, professionals are often expected to have a grasp of:\n\n* **AI Engineering and LLMs**: The rise of generative AI and LLMs (Large Language Models) has added a new layer of complexity.\n\n* **Full-Stack Development**: Some companies seek \"full-stack Data Scientists\" who can build models and develop the front-end or back-end systems that deploy these models.\n\n## Issue #4: The Data Quality Problem\n\n> Ah, data, my dear friend, foe, and partner. What would I do without you? Use LLMs to generate data, perhaps? But that can be bad, you say?  \n> ‚Äî **Random Data Scientist in 2024**\n\n![Fig 4. Garbage in equals Garbage out](/images/blog/unpopular-opinion-hard-good-ds/pic_issue_4.png)\n\n*Fig 4. Garbage in equals Garbage out. Source: Author.*\n\n\u003CCallout type=\"error\" title=\"The GIGO Principle\">\nGarbage in equals garbage out‚Äîlet's repeat it: **GIGO, GIGO**. Data quality is and will remain a critical issue at many companies, even if you use all the cool LLM-based features available today. If there's no data strategy or plan to make data accessible, the quality of the model doesn't matter.\n\u003C/Callout>\n\nFrom my experience, almost every place I've worked has had issues with data, whether it's about quality, accessibility, or integration.\n\nThere's a long-standing belief that a Data Scientist spends **80%** of their time cleaning data and only **20%** on actual analysis and modeling. This idea, popularized through various surveys, still holds some truth, even though things have drastically improved over recent years.\n\nHowever, it's still surprising that so many companies don't fully understand their data, where it resides, how it's generated, and its quality. Without a clear data management strategy, even the most advanced machine learning models will struggle to produce reliable, actionable insights.\n\n## Issue #5: The need for deep domain knowledge \n\n> Aren't you a \"scientist\"? Shouldn't you know everything by heart, i.e., legal, finance, sourcing, etc.? It can't be that hard. I have worked with this for 10+ years, so I shouldn't have to tell you how the domain works; use ChatGPT. Why should I provide guidance and help you with labeling?\n> ‚Äî **Random Domain Expert 2022-2023**\n\n![Fig 5. Data Scientists also needs to be Domain Scientists](/images/blog/unpopular-opinion-hard-good-ds/pic_issue_5.png)\n\n*Fig 5. Data Scientists also needs to be Domain Scientists. Source: Author.*\n\nThere is a massive potential for LLMs and LLM Agents. Who knows‚Äîthis might be the cusp of achieving AGI (*Artificial General Intelligence*) or even ASI (*Artificial Superintelligence*). But, even with this optimism, I still see LLMs and agents having a hard time in their current form becoming genuine generalist problem solvers. This means that profound domain expertise will continue to be essential in the coming years.\n\nHowever, being a data scientist, it's challenging to be a legal or finance expert or possess in-depth knowledge of other adjacent domains. This is where collaboration becomes crucial. Working alongside domain experts will be even more critical, as their insights can guide the proper framing of problems, ensure that data-driven solutions are relevant, and help validate AI model outcomes.\n\n### The Role of Domain Experts in AI Projects\n\n* **Contextual Understanding**: Domain experts provide the context often missing in pure data analysis.\n\n* **Fine-Tuning AI Models**: When building LLMs or other AI solutions, domain knowledge can aid in fine-tuning, ensuring that the models generate outputs that align with industry standards and real-world applications.\n\n* **Mitigating Risks and Ensuring Compliance**: In sectors like finance, healthcare, and law, there are strict compliance requirements.\n\n\u003CCallout type=\"note\" title=\"Collaboration is Key\">\nWhile LLMs and other AI tools continue to advance, deep domain knowledge remains crucial for success. For Data Scientists, **collaboration with domain experts is not just a best practice‚Äîit's a necessity**.\n\u003C/Callout>\n\n## Issue #6: DataOps, MLOps, AIOps, LLMOps, or Just DevOps?\n\n> \"Wait, so you're telling me I need to understand how data pipelines work, manage model deployment, optimize LLMs, AND maintain cloud infrastructure? I thought I just needed to train a model! Can we call it 'Ops' and pretend I know what I'm doing?\" ‚Äî **Random Data Scientist in 2024**\n\n![Fig 6. Why not keep it simple and call it Ops?](/images/blog/unpopular-opinion-hard-good-ds/pic_issue_6.png)\n\n*Fig 6. Why not keep it simple and call it Ops? Source: Author.*\n\nI'm a big advocate of end-to-end (E2E) ML systems, and you can find more of my thoughts on this topic in my previous writings. In these systems, the AI or ML component is often a small but critical part of a larger ecosystem that requires testing, monitoring, tracing, and other operational practices. This still holds for LLM-based systems, giving rise to the now-growing field of LLMOps.\n\nHowever, it can be rather discombobulating for practitioners to differentiate between MLOps, DataOps, AIOps, and LLMOps. Aren't these just variations of DevOps? In my experience, what you call it matters less than understanding the need to operationalize these stochastic systems effectively.\n\n### Breaking Down the Terminology: What's the Difference?\n\n* **DataOps**: Primarily focused on managing data pipelines and workflows. DataOps ensures that data is accessible, reliable, and clean.\n  \n* **MLOps**: A blend of DevOps and machine learning, MLOps focuses on automating and streamlining the deployment, monitoring, and management of machine learning models.\n  \n* **AIOps**: Combines AI with IT operations to automate performance monitoring, anomaly detection, and alert management tasks.\n  \n* **LLMOps**: An emerging field specifically focused on operationalizing Large Language Models. It involves all the principles of MLOps but adds layers unique to LLMs.\n\n## Issue #7: The Impact of Rapid Technological Change\n\n> \"Wait, so the new library/model or LLM isn't compatible with our current stack, but is it faster and cheaper? It can reason, you say... Awesome. I'll just figure out how to make it fit, like a square peg in a round hole.\" - **Problem-Solving EM, 2024**\n\n![Fig 7. Too many languages, frameworks and models to keep track off](/images/blog/unpopular-opinion-hard-good-ds/pic_issue_7_v2.png)\n\n*Fig 7. Too many languages, frameworks and models to keep track off. Source: Author.*\n\nIf you have chosen the path of a Data Scientist, you're likely someone who enjoys learning and experimenting with new technology. However, compared to a few years ago, the pace of change in this field has accelerated drastically. We see new research papers released almost daily and new libraries that promise to do things better than before.\n\nThe choices don't stop there. Should you buy or build? Fine-tune or prompt-engineer, especially as LLM capabilities continue to improve? What tasks are still considered core to Data Science?\n\nMy point is that **technology**‚Äîand **Data Science** with it‚Äîcontinues to change rapidly. And we as practitioners need to stay ahead of the curve and adopt a continuous learning mind set.\n\n### Key Challenges and Considerations\n\n* **Overwhelming Choice of Tools and Technologies**: With the rapid release of new programming languages, frameworks, and libraries, Data Scientists face the daunting task of deciding which tools to invest their time.\n  \n* **Fragmentation and Integration**: The sheer number of tools can lead to fragmentation, where teams might struggle to integrate different systems.\n  \n* **Evolving Skillsets**: The skillset required for Data Scientists continues to evolve. It's no longer just about building models.\n  \n* **Balancing Innovation and Practicality**: The fast pace of change means that businesses often feel pressured to adopt the latest technologies.\n\n## Closing remarks\n\nAs the field of data science continues to grow and evolve, so do the challenges that come with it. The introduction of GenAI, Large Language Models, and the increasing demand for AI-driven solutions have brought new opportunities and heightened expectations. **Companies want to leverage AI to gain a competitive edge, but many still need the foundational strategies and support systems to make that a reality**.\n\nFor data scientists, ML Engineers, and recently AI Engineers, this means adapting to an ever-shifting landscape where skills once considered niche, such as understanding system architecture or working with domain experts, have become essential. **The days of focusing purely on building models are over** and have been over for some time.\n\nHowever, the journey has its pitfalls. The hype around AI has created a perception that it's easier than ever to implement sophisticated solutions, leading to a rise in **\"overnight experts\"** and an over-reliance on plug-and-play tools.\n\nAs AI continues to develop, so will the need for **robust DataOps, MLOps, and LLMOps frameworks** that ensure these systems are scalable, secure, and reliable. At the same time, the pace of technological change means data scientists must constantly learn and adapt.\n\nIn the end, being a **\"good\" data scientist in today's world** requires more than technical skill‚Äîit requires an understanding of the business landscape, a willingness to collaborate with diverse teams, and, above all, a drive to keep learning.\n\nThe future of data science is bright‚Äîjust as soon as we figure out what the job entails, now and in the future. One day, you're cleaning data; the next, you're explaining to your boss why their AI chatbot can't \"just read minds.\" But if you love learning new frameworks, battling tech buzzwords, and trying to convince everyone that data privacy is non-essential, congrats‚Äîyou've chosen the right field.\n\nSo grab your favorite Python package, keep an eye on the latest LLM breakthrough, and remember: **A great data scientist doesn't just solve problems‚Äîthey convince everyone that they never created them in the first place**.","src/content/blog/unpopular-opinion-hard-good-ds.mdx","126df1d1360be2d6","unpopular-opinion-hard-good-ds.mdx",true,"prompt-eng-ner",{"id":29,"data":31,"body":41,"filePath":42,"digest":43,"legacyId":44,"deferredRender":28},{"title":32,"description":33,"pubDate":34,"updatedDate":35,"tags":36,"author":23},"Prompt Engineering for Named Entity Recognition (NER)","Prompt Engineering Tips & Tricks for Named Entity Recognition (NER). Learn how to effectively extract entities from text using Large Language Models with practical techniques and examples.",["Date","2024-01-21T00:00:00.000Z"],["Date","2024-01-27T00:00:00.000Z"],[20,37,38,39,40],"Generative AI","Prompt Engineering","NER","Natural Language Processing","import Callout from '@components/Callout.astro';\n\n**2023** was the year of *exploration*, *testing* and *proof-of-concepts* or deployment of smaller LLM-powered workflows/use cases for many organizations. Whilst 2024 will likely be the year where we will see even more production systems leveraging LLMs. Compared to a traditional ML system where data (examples, labels), model and weights are some of the main artifacts, prompts are instead the **main** artifacts. Prompts and prompt engineering are fundamental in driving a certain behavior of an assistant or agent, for your use case.\n\nTherefore many of the large players as well as academia have provided guides on how to prompt LLMs efficiently:\n1. üíª [OpenAI Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering)\n2. üíª [Guide to Anthropic's prompt engineering resources](https://docs.anthropic.com/claude/docs/guide-to-anthropics-prompt-engineering-resources)\n3. üíª [Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4](https://arxiv.org/abs/2312.16171)\n4. üíª [Prompt Engineering Guide](https://www.promptingguide.ai/)\n\nMany of these guides are quite **generic** and can work for many different use cases. However, there are very few guides mentioning best practices for constructing prompts for *Named Entity Recognition (NER)*. OpenAI has for instance a [cookbook](https://cookbook.openai.com/examples/named_entity_recognition_to_enrich_text) for `NER`  as well as [this](https://arxiv.org/pdf/2305.15444.pdf) and [this](https://arxiv.org/pdf/2310.17892.pdf) paper which both suggested a method called `Prompt-NER`. \n\nIn this article, we will discuss some techniques that might be helpful when using LLM for NER use cases. To set the stage we will first start with defining what *Prompt Engineering* and *Named Entity Recognition* are.\n\n## Prompt Engineering\n\nPrompt Engineering sometimes feels more like an *art* compared to *science* but there are more best practices showing up (see some of the *references* in the previous section). \n\nOne definition of `Prompt Engineering` is shown below:\n\n\u003CCallout type=\"info\" title=\"Definition: Prompt Engineering\">\n**Prompt engineering** is a relatively new discipline for developing and optimizing prompts to efficiently use language models (LMs) for a wide variety of applications and research topics. Prompt engineering skills help to better understand the capabilities and limitations of large language models (LLMs).\n\nPrompt engineering is not just about designing and developing prompts. It encompasses a wide range of skills and techniques that are useful for interacting and developing with LLMs. It's an important skill to interface, build with, and understand the capabilities of LLMs. You can use prompt engineering to improve the safety of LLMs and build new capabilities like augmenting LLMs with domain knowledge and external tools.\n\n‚Äî *Prompt Engineering Guide*\n\u003C/Callout>\n\nLike any other artifact prompts may be \"outdated\" or \"drift\" which is why it is important to have systems in place to do the:\n* *Experiment* tracking of prompts\n* *Evaluating* your prompts (either via the \"*golden dataset*\" approach, LLM-based *evals* or both)\n* *Observability* of how your prompts are being used\n* *Versioning* of your prompts. \n\n## Named Entity Recognition (NER)\n\nExtracting `entities` or `tags` from data can be very useful for many different domains and businesses and can be used for many different things such as *classification*, *knowledge retrieval*, *search* etc.\n\nSee one definition below for `Named Entity Recognition`:\n\n\u003CCallout type=\"info\" title=\"Definition: Named Entity Recognition\">\n**Named Entity Recognition (NER)** is a task of Natural Language Processing (NLP) that involves identifying and classifying named entities in a text into predefined categories such as person names, organizations, locations, and others. The goal of NER is to extract structured information from unstructured text data and represent it in a machine-readable format. Approaches typically use **BIO** notation, which differentiates the beginning (B) and the inside (I) of entities. O is used for non-entity tokens.\n\n‚Äî *Papers with Code*\n\u003C/Callout>\n\nBelow is an example of the **BIO** notation, which is a common format used for NER:\n\n```shell\nMac [B-PER]\nDoe [I-PER]   \nate [O]\na [O]\nhamburger [O] \nat [O]\nMcdonalds [B-LOC]\n```\n\nHowever, the BIO notation does not make sense for all use cases. Let's say that if you are interested in extracting *food* entities then *hamburger* above might be a **key** entity or tag that you want to predict.\n\nUsually, a \"typical\" NER pipeline comprises the following steps:\n1. `tokenizer`: Turn text into *tokens*\n2. `tagger`: Assign part of speech tags\n3. `parser`: Assign *dependency* labels\n4. `ner`: Detect and label named entities\n\nSolving NER systems has previously been done by using:\n1. Rule-based systems\n2. Statistical & ML systems\n3. Deep-Learning systems\n4. Mix of (1) - (3).\n\nWhere [spacy](https://spacy.io/) and Transformer architectures from e.g. [HuggingFace](https://huggingface.co/) such as *BERT*, *XLM-ROBERta* etc. have been the go-to methods or architectures.\n\nBefore we start with prompt engineering let's set the stage with an example use case. \n\n### Food Entities from recipes \n\nIn the following section we will assume the following:\n1. We are a food tech startup that provides and sells custom smart purchase lists to retailers from online food recipes.\n2. We want to extract the following type of entities: `FOOD`, `QUANTITY`, `UNIT`, `PHYSICAL_QUALITY`, `COLOR`\n3. When we have the `entities` we want to populate smart purchase lists with recommendations on where to get the food.\n\nThe example [recipe](https://www.carolinescooking.com/chashu-pork/#recipe) that we will be using:\n\n```markdown\n### Chashu pork (for ramen and more)\nChashu pork is a classic way to prepare pork belly for Japanese dishes such as ramen. \nWhile it takes a little time, it's relatively hands-off and easy, and the result is delicious.\n\n### Ingredients\n2 lb pork belly or a little more/less\n2 green onions spring onions, or 3 if small\n1 in fresh ginger (a chunk that will give around 4 - 6 slices)\n2 cloves garlic\n‚Öî cup sake\n‚Öî cup soy sauce\n¬º cup mirin\n¬Ω cup sugar\n2 cups water or a little more as needed\n\n### Instructions\nHave some string/kitchen twine ready and a pair of scissors before you prepare the pork. \nIf needed, trim excess fat from the outside of the pork but you still want a later over the\n...\n```\n\n## Technique #1 - Use `temperature=0.0`\n\nLLMs are *non-deterministic* by nature and different generations of using e.g. chat completions APIs from e.g. `OpenAI` will return different responses. However, one way to mitigate this is to use the `temperature` parameter often provided in these types of APIs. In short, the *lower* the temperature, the more **deterministic** the results in the sense that the highest probable next token is always picked. Do notice that this is still not a guarantee for deterministic output. Rather the *best try effort* to always select the *most likely token* as model output.\n\nThis is of course useful in a NER case where you would like the same or similar input to produce the same or similar output.\n\n\u003CCallout type=\"success\" title=\"Tip 1: Temperature Control\">\nUse `temperature=0.0` to get more **deterministic** output:\n\n- Lower temperature = more predictable responses\n- Higher temperature = more creative/random responses  \n- For NER tasks, you want consistency, so use `0.0`\n\u003C/Callout>\n\n## Technique #2 - Set `seed` for your runs\n\nRecently OpenAI added the functionality to set the [seed](https://cookbook.openai.com/examples/reproducible_outputs_with_the_seed_parameter) to make runs more reproducible. If all other params are set to the same value e.g. `temperature=0` etc, `seed` is set and the `system_fingerprint` then output will be mostly deterministic.\n\n\u003CCallout type=\"success\" title=\"Tip 2: Seed Control\">\nSet `seed` parameter for **reproducible** results:\n\n```python\nresponse = openai.chat.completions.create(\n  model=\"gpt-4\",\n  temperature=0.0,\n  seed=42,  # Same seed = same output\n  messages=[...]\n)\n```\n\n*Note: Only works when combined with `temperature=0` and same `system_fingerprint`.*\n\u003C/Callout>\n\nBoth the previous section and this section were more focused on model parameters. The following sections will instead focus on what `Prompt Engineering` techniques we can use to extract named entities.\n\n## Technique #3 - Use clear instructions\n\nThe next step is to use `clear` instructions to the agent normally:\n* `System` prompt is used for instructions\n* `User` prompt to provide context and data\n* (`Assistant`) prompt to provide examples\n\nStarting with a prompt like the below:\n\n```markdown\nSystem:\nYou are a food AI assistant who is an expert in natural language processing\nand especially name entity recognition.\n\nUser:\nExtract all food-related entities from the recipe below in backticks:\n```{recipe}```\n...\n```\n\nWe get the following output:\n\n```markdown\n#### extract_food_entities\nI will now proceed to extract all the food-related entities from the given recipe.\n\n#### extract_food_entities\nThe food-related entities present in the recipe are as follows:\n\n* Pork belly\n* Green onions\n* Fresh ginger\n* Garlic\n* Sake\n* Soy sauce\n* Mirin\n* Sugar\n* Water\n* Rice\n\nThese entities cover the main ingredients used for the Chashu pork recipe.\n```\n\nYou can also use the `Assistant` message to prompt with some examples:\n\n```markdown\nAssistant:\nExample:\n```json\n{\n  \"food\": \"minced meat\",\n  \"quantity\": 500\n  \"unit\": grams (g)\n  \"physicalQuality\": \"minced\",\n  \"color\": \"brown\"\n}\n```\n...\n\n\u003CCallout type=\"success\" title=\"Tip 3\">\nUse **clear instructions** to guide the LLM effectively:\n\n- Use `System` prompt for instructions\n- Use `User` prompt to provide context and data  \n- Use `Assistant` prompt to provide examples\n\nThis structured approach helps the model understand exactly what you want it to do.\n\u003C/Callout>\n\n## Technique #4 - Use `functions` or `tools`\n\nWhen we use `functions` or `tools` we prompt the model to provide input **arguments** for an actual function in a downstream manner. This is similar to what is mentioned in section 4.2 here. You can use these arguments as they are (as they will be valid `JSON`) or do some further processing by doing the function calling in your logic. One example could be that we want to trigger certain actions or do certain formatting based on the function arguments.\n\nThe functions will also be part of the system prompt. Many of the latest models have been fine-tuned to work with function calling and thus produce valid `JSON` output in that way. To define a function we define a `jsonSchema` as below:\n\n```json\n{\n  \"name\": \"extract_food_entities\",\n  \"description\": \"You are a food AI assistant. Your task is to extract food entities from a recipe based on the JSON schema. You are to return the output as valid JSON.\",\n  \"parameters\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"food-metadata\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"food\": {\n            \"type\": \"string\",\n            \"description\": \"The name of the food item\"\n          },\n          \"quantity\": {\n            \"type\": \"string\",\n            \"description\": \"The quantity of the food item\"\n          },\n          \"unit\": {\n            \"type\": \"string\",\n            \"description\": \"The unit of the food item\"\n          },\n          \"physicalQuality\": {\n            \"type\": \"string\",\n            \"description\": \"The physical quality of the food item\"\n          },\n          \"color\": {\n            \"type\": \"string\",\n            \"description\": \"The color of the food item\"\n          }\n        },\n        \"required\": [\n          \"food\", \n          \"quantity\",\n          \"unit\",\n          \"physicalQuality\",\n          \"color\"\n        ]\n      }\n    },\n    \"required\": [\n      \"food-metadata\"\n    ]\n  }\n}\n```\n\nThe example output of using the `extract_food_entities` below is:\n\n```json\n{\n    \"food-metadata\": {\n        \"food\": \"Pork Belly\",\n        \"quantity\": \"2\",\n        \"unit\": \"lb\",\n        \"physicalQuality\": \"-\",\n        \"color\": \"-\"\n    }\n}\n```\n\n\u003CCallout type=\"success\" title=\"Tip 4\">\nUse `tools` or `function` calling with a `jsonSchema` to extract wanted metadata.\n\u003C/Callout>\n\n## Technique #5 - Use domain prompts \n\nAs seen above using the `jsonSchema` above gives us metadata in a structured format that we can use for downstream processing. However, there are some limitations in the number of characters you can set in the description for each `property` in the `jsonSchema`. One way to give further instructions to the LLM is to add `domain-specific` instructions to e.g. the `system` prompt:\n\n```markdown\nSystem:\nYou are a food AI assistant who is an expert in natural language processing\nand especially name entity recognition. The entities we are interested in are: \"food\", \"quantity\", \"unit\", \"physicalQuality\" and \"color\". \n\nSee further instructions below for each entity:\n\n\"food\": This can be both liquid and solid food such as meat, vegetables, alcohol, etc. \n\n\"quantity\": The exact quantity or amount of the food that should be used in the recipe. Answer in both full units such as 1,2,3, etc but also fractions e.g. 1/3, 2/4, etc. \n\n\"unit\": The unit being used e.g. grams, milliliters, pounds, etc. The unit must always be returned.\n\n\"physicalQuality\": The characteristic of the ingredient (e.g. boneless for chicken breast, frozen for\nspinach, fresh or dried for basil, powdered for sugar).\n\n\"color\": The color of the food e.g. green, black, white. If no color is identified respond with colorless.\n\nUser:\nExtract all food-related entities from the recipe below in backticks:\n```{recipe}```\n...\n```\n\nExample output with this update prompt is shown below:\n\n```json\n{\n    \"food-metadata\": {\n        \"food\": \"pork belly\",\n        \"quantity\": \"2 lb\",\n        \"unit\": \"pound\",\n        \"physicalQuality\": \"raw\",\n        \"color\": \"colorless\"\n    }\n}\n\n{\n    \"food-metadata\": {\n        \"food\": \"green onions\", \n        \"quantity\": \"2\",\n        \"unit\": \"pieces\",\n        \"physicalQuality\": \"fresh\",\n        \"color\": \"green\"\n    }\n}\n```\n\n\u003CCallout type=\"success\" title=\"Tip 5\">\nIncorporate `domain` knowledge to help the LLM with extracting the entities you are looking for.\n\u003C/Callout>\n\n## Technique #6 - Use Chain-of-Thought\n\n\u003CCallout type=\"info\" title=\"Chain-of-Thought (CoT)\">\n**Chain-of-Thought** (CoT) is a prompting technique where each input question is followed by an intermediate reasoning step, that leads to the final answer. This shown to improve the the output from LLMs. There is also a slight variation of CoT called *Zero-Shot Chain-of-Thought* where you introduce **\"Let's think step by step\"** to guide the LLM's reasoning.\n\u003C/Callout>\n\nAn update to the prompt now using *Zero-Shot Chain-of-Thought* would be:\n\n```markdown\nSystem:\nYou are a food AI assistant who is an expert in natural language processing\nand especially name entity recognition. The entities we are interested in are: \"food\", \"quantity\", \"unit\", \"physicalQuality\" and \"color\". \n\nSee further instructions below for each entity:\n\n\"food\": This can be both liquid and solid food such as meat, vegetables, alcohol, etc. \n\n\"quantity\": The exact quantity or amount of the food that should be used in the recipe. Answer in both full units such as 1,2,3, etc but also fractions e.g. 1/3, 2/4, etc. \n\n\"unit\": The unit being used e.g. grams, milliliters, pounds, etc. The unit must always be returned.\n\n\"physicalQuality\": The characteristic of the ingredient (e.g. boneless for chicken breast, frozen for\nspinach, fresh or dried for basil, powdered for sugar).\n\n\"color\": The color of the food e.g. green, black, white. If no color is identified respond with colorless.\n\nLet's think step-by-step.\n\nUser:\nExtract all food-related entities from the recipe below in backticks:\n```{recipe}```\n...\n```\n\nBy adding **\"Let's think step by step\"** we can see some slight improvements for the extraction:\n\n```json\n{\n    \"food-metadata\": {\n        \"food\": \"pork belly\", \"quantity\": \"2 lb\",\n        \"unit\": \"ounce\",\n        \"physicalQuality\": \"trimmed\",\n        \"color\": \"colorless\"\n    }\n}\n```\n\nTrimmed is likely a better `physicalQuality` to describe the pork belly, instead of `raw`. This as the pork belly is sliced and used as a topping e.g. a bowl of ramen.\n\n\u003CCallout type=\"success\" title=\"Tip 6\">\n`Chain-of-thought` may improve performance, especially for fields that need some calculation or reasoning steps.\n\u003C/Callout>\n\n## Technique #7 - Use Prompt Chaining\n\n\u003CCallout type=\"info\" title=\"Prompt Chaining\">\nTo improve the reliability and performance of LLMs, one of the important prompting engineering techniques is to break tasks into subtasks. Once those subtasks have been identified, the LLM is prompted with a subtask and then its response is used as input to another prompt. This is what's referred to as prompt chaining where a task is split into subtasks with the idea to create a chain of prompt operations.\n\n‚Äî *Prompt Engineering Guide*\n\u003C/Callout>\n\n*Prompt Chaining* is somewhat similar to CoT here with the idea of breaking down the problem into sub-problems or tasks. However, the main difference here is that one prompt outputs its response from a previous prompt to the next prompt as refined context.\n\nIn our recipe example, we might construct a prompt looking like the below:\n\n```python\nCONTEXT_PROMPT = \"\"\"\nYou are a food AI assistant who is an expert in natural language processing\nand especially named entity recognition. The entities we are interested in are: \"food\", \"quantity\", \"unit\", \"physicalQuality\" and \"color\". \n\nYour task is to extract the entity, the value of the entity and the reasoning, \nfor why the extracted value is the correct value. \nIf you cannot extract the entity add \"N/A\".\n\nMake sure to output the results according to the output format below.\n\n\u003CFood-Metadata>:\n\"\u003Cmetadata>\":\n- Entity: // the actual entity i.e. pork, onions etc\n- Value: // Value of the metadata field\n- Reasoning: // Reasoning for why the entity is correct.\n\nLet's think step-by-step.\n\"\"\"\n```\n\nThe output from the first prompt is:\n\n```markdown\n\"pork\":\n- Entity: food\n- Value: pork belly\n- Reasoning: The text mentions preparing pork belly for Japanese dishes such as ramen, and the recipe specifically calls for 2 lb of pork belly.\n\n\"green onions\":\n- Entity: food\n- Value: green onions\n- Reasoning: The text mentions using 2 green onions and specifies that 3 should be used if they are small.\n\n\"ginger\":\n- Entity: food\n- Value: ginger\n- Reasoning: The recipe specifies using 1 inch of fresh ginger.\n\n\"garlic\":\n- Entity: food\n- Value: garlic\n- Reasoning: The recipe specifies using 2 cloves of garlic.\n\n\"sake\":\n- Entity: food\n- Value: sake\n- Reasoning: The recipe calls for ‚Öî cup of sake.\n\n\"soy sauce\":\n- Entity: food\n- Value: soy sauce\n- Reasoning: The recipe calls for ‚Öî cup of soy sauce.\n\n\"mirin\":\n- Entity: food\n- Value: mirin\n- Reasoning: The recipe calls for ¬º cup of mirin.\n\n\"sugar\":\n- Entity: food\n- Value: sugar\n- Reasoning: The recipe calls for ¬Ω cup of sugar.\n\n\"water\":\n- Entity: food\n- Value: water\n- Reasoning: The recipe specifies using 2 cups of water.\n```\n\nWe then use the output from the prompt above as input to our `extract_food_entities` prompt from before. This approach may be helpful when you have entities that need to be calculated with some reasoning around them or they may not be in the exact format that you have in your JSON schema.\n\n\u003CCallout type=\"success\" title=\"Tip 7\">\n`Prompt-Chaining` can help as an import pre-processing step to provide more relevant context.\n\u003C/Callout>\n\n## Closing Remarks\n\nIn this post, we have been walking through some useful prompt-engineering techniques that might be helpful when you deal with Named Entity Recognition (NER) using LLMs such as OpenAI. \n\n\u003CCallout type=\"note\" title=\"Key Takeaways\">\nDepending on your use-case one or several of these techniques may help improve your NER solution. However, writing clear instructions, using CoT and or prompt chaining together with `tools` or `functions` tend to improve the NER extraction.\n\u003C/Callout>","src/content/blog/prompt-eng-ner.mdx","1078b574ca3797a1","prompt-eng-ner.mdx","ner-dspy",{"id":45,"data":47,"body":54,"filePath":55,"digest":56,"legacyId":57,"deferredRender":28},{"title":48,"description":49,"pubDate":50,"updatedDate":51,"tags":52,"author":23},"NER using DSPy","Using DSPy for extracting metadata data using NER - Learn how to use DSPy framework for Named Entity Recognition tasks instead of traditional prompt engineering approaches.",["Date","2024-04-01T16:15:31.000Z"],["Date","2024-04-01T16:15:31.000Z"],[20,37,38,39,53,40],"DSPy","import Callout from '@components/Callout.astro';\n\nAnyone, who has been working with LLMs and generative AI recently has noticed that how you *prompt* an LLM matters. Slight changes to your prompts might lead to unexpected results. It is often *non-trivial* to reuse the same prompts when switching the underlying LLM you are using. An example is e.g. moving from `OpenAI` to `Anthropic` and using `function` calling. \n\nThis often leads to quite some time spent on rewriting your prompts, thus more prompt engineering is required. Luckily, there are some interesting frameworks out there such as [DSPy](https://dspy-docs.vercel.app/) that focus more on *'programming'* rather than *'prompting'* your LLMs.\n\nTo get a good overview of `DSPy` see some of the references below:\n1. üíª [Intro to DSPy: Goodbye Prompting, Hello Programming!](https://towardsdatascience.com/intro-to-dspy-goodbye-prompting-hello-programming-4ca1c6ce3eb9)\n2. üíª [DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines](https://arxiv.org/abs/2310.03714)\n3. üíª [DSPy Deep-Dive](https://dspy-docs.vercel.app/docs/category/deep-dive)\n\nIn this post, we will try to use `DSPy` to extract metadata data from recipes. For a recap of our previous approach see e.g. this [post](/blog/prompt-eng-ner#food-entities-from-recipes).\n\n## DSPy - Declarative Self-improving Language Programs\n`DSPy` or *Declarative Self-improving Language Programs* was first introduced in the paper in (2):\n\n\u003CCallout type=\"info\" title=\"About DSPy\">\n`DSPy` is a framework for algorithmically **optimizing** LM prompts and weights, especially when LMs are used one or more times within a pipeline.\n\n`DSPy` can routinely teach powerful models like `GPT-3.5` or `GPT-4` and local models like `T5-base` or `Llama2-13b` to be much more **reliable** at tasks, i.e. having higher quality and/or avoiding specific failure patterns. DSPy optimizers will **\"compile\"** the same program into different instructions, few-shot prompts, and/or weight updates (finetunes) for each LM\n\n‚Äî *DSPy Documentation*\n\u003C/Callout>\n\nNote the use of `optimizing` above as this provides some analogies to `optimizing` neural networks using a framework such as `Pytorch` or `Tensorflow`. The nice thing with the `optimizer` above is that `DSPy` enables us to not focus too much on `prompt engineering` with whatever LLM we choose. Instead, we can `compile` i.e. optimize the underlying instructions to work with any LLM.\n\nIn short, the `DSPy` programming model has the following abstractions:\n1. [Signatures](https://dspy-docs.vercel.app/docs/building-blocks/signatures) instead of the needed for hand-written prompts/fine-tuning.\n2. [Modules](https://dspy-docs.vercel.app/docs/building-blocks/modules) that implement various prompt engineering techniques such as [Cot](https://dspy-docs.vercel.app/api/modules/ChainOfThought), [REACT](https://dspy-docs.vercel.app/api/modules/ReAct) etc.\n3. [Optimizer](https://dspy-docs.vercel.app/docs/building-blocks/optimizers) to automated manual prompt engineering based on given [metrics](https://dspy-docs.vercel.app/docs/building-blocks/metrics)\n\nA `DSPy` program is a program using (1) - (3) together with data to use in the optimization step. For a more thorough walk-through of `DSPy` see e.g., (1) and (2) from the introduction section.\n\n## NER using DSPy, extracting food-related entities\nIn the following sections, we will use this [notebook](https://github.com/MarcusElwin/ner-dspy) üìì to examine how you can use `DSPy` for `NER` use cases. As in the previous NER post, we want to extract different metadata for food items.\n\n### Setup environment\nThe first thing to do is to load the necessary libraries and do any setup of these libraries.\n\n```python\nimport dspy\nfrom pydantic import BaseModel, Field\nfrom dspy.functional import TypedPredictor\nfrom IPython.display import Markdown, display\nfrom typing import List, Optional, Union\nfrom dotenv import load_dotenv\nfrom devtools import pprint\n\nassert load_dotenv() == True\ngpt4 = dspy.OpenAI(model=\"gpt-4-turbo-preview\", max_tokens=4096, model_type=\"chat\")\ngpt_turbo = dspy.OpenAI(model=\"gpt-3.5-turbo\", max_tokens=4096, model_type=\"chat\")\ndspy.settings.configure(lm=gpt4)\n```\n\nHere we use `OpenAI` for the example. `DSPy` seems to support many of the big open/closed source providers. For implementations see more [here](https://github.com/stanfordnlp/dspy/tree/main/dsp/modules) and [here](https://github.com/stanfordnlp/dspy/blob/main/dspy/__init__.py)\n\n### Data\nAs in this [post](/blog/prompt-eng-ner#food-entities-from-recipes), we will use the data shown below:\n\n```markdown\n### Chashu pork (for ramen and more)\nChashu pork is a classic way to prepare pork belly for Japanese dishes such as ramen. \nWhile it takes a little time, it's relatively hands-off and easy, and the result is delicious.\n\n### Ingredients\n2 lb pork belly or a little more/less\n2 green onions spring onions, or 3 if small\n1 in fresh ginger (a chunk that will give around 4 - 6 slices)\n2 cloves garlic\n‚Öî cup sake\n‚Öî cup soy sauce\n¬º cup mirin\n¬Ω cup sugar\n2 cups water or a little more as needed\n\n### Instructions\nHave some string/kitchen twine ready and a pair of scissors before you prepare the pork. \nIf needed, trim excess fat from the outside of the pork but you still want a later over the\n...\n```\n\nWe will also use the following `Pydantic` data models as part of the problem:\n\n```python\nclass FoodMetaData(BaseModel):\n    reasoning: str = Field(description=\"Reasoning for why the entity is correct\")\n    value: Union[str, int] = Field(description=\"Value of the entity\")\n    entity: str = Field(description=\"The actual entity i.e. pork, onions etc\")\n\nclass FoodMetaData(BaseModel):\n    context: List[FoodMetaData]\n```\n\nThe first model above represents the \"reasoning\" object as part of the CoT step in the workflow.\n\n\u003CCallout type=\"note\" title=\"Pydantic Integration\">\n`DSPy` seems to be relying on `Pydantic` for many things in the library.\n\u003C/Callout>\n\n```python\nclass FoodEntity(BaseModel):\n    food: str = Field(description=\"This can be both liquid and \\\n    solid food such as meat, vegetables, alcohol, etc\")\n    quantity: int = Field(description=\"The exact quantity or amount \\\n    of the food that should be used in the recipe\")\n    unit: str = Field(description=\"The unit being used e.g. \\\n    grams, milliliters, pounds, etc\")\n    physical_quality: Optional[str] = Field(description=\"The characteristic of the ingredient\")\n    color: str = Field(description=\"The color of the food\")\n\nclass FoodEntities(BaseModel):\n    entities: List[FoodEntity]\n```\n\nThe second model above is the schema for the actual metadata that we want to extract. Below is the resulting `JSON` schema for this object:\n\n```json\n{\n    \"properties\": {\n        \"food\": {\n            \"description\": \"This can be both liquid and solid food such as meat, vegetables, alcohol, etc\",\n            \"title\": \"Food\",\n            \"type\": \"string\"\n        },\n        \"quantity\": {\n            \"description\": \"The exact quantity or amount of the food that should be used in the recipe\",\n            \"title\": \"Quantity\",\n            \"type\": \"integer\"\n        },\n        \"unit\": {\n            \"description\": \"The unit being used e.g. grams, milliliters, pounds, etc\",\n            \"title\": \"Unit\",\n            \"type\": \"string\"\n        },\n        \"physical_quality\": {\n            \"anyOf\": [\n                {\n                    \"type\": \"string\"\n                },\n                {\n                    \"type\": \"null\"\n                }\n            ],\n            \"description\": \"The characteristic of the ingredient\",\n            \"title\": \"Physical Quality\"\n        },\n        \"color\": {\n            \"description\": \"The color of the food\",\n            \"title\": \"Color\",\n            \"type\": \"string\"\n        }\n    },\n    \"required\": [\n        \"food\",\n        \"quantity\",\n        \"unit\",\n        \"physical_quality\",\n        \"color\"\n    ],\n    \"title\": \"FoodEntity\",\n    \"type\": \"object\"\n}\n```\n\nFinally, for the teleprompter/optimizer, we need to provide some training examples:\n\n```python\n# create some dummy data for training\ntrainset = [\n    dspy.Example(\n        recipe=\"French omelett with 2 eggs, 500grams of butter and 10 grams gruyere\", \n        entities=[\n            FoodEntity(food=\"eggs\", quantity=2, unit=\"\", physical_quality=\"\", color=\"white\"),\n            FoodEntity(food=\"butter\", quantity=500, unit=\"grams\", physical_quality=\"\", color=\"yellow\"),\n            FoodEntity(food=\"cheese\", quantity=10, unit=\"grams\", physical_quality=\"gruyer\", color=\"yellow\")\n        ]\n    ).with_inputs(\"recipe\"),\n    dspy.Example(\n        recipe=\"200 grams of Ramen noodles bowel with one pickled egg, 500grams of pork, and 1 spring onion\", \n        entities=[\n            FoodEntity(food=\"egg\", quantity=1, unit=\"\", physical_quality=\"pickled\", color=\"ivory\"),\n            FoodEntity(food=\"ramen nudles\", quantity=200, unit=\"grams\", physical_quality=\"\", color=\"yellow\"),\n            FoodEntity(food=\"spring onion\", quantity=1, unit=\"\", physical_quality=\"\", color=\"white\")\n        ]\n    ).with_inputs(\"recipe\"),\n    dspy.Example(\n        recipe=\"10 grams of dutch orange cheese, 2 liters of water, and 5 ml of ice\", \n        entities=[\n            FoodEntity(food=\"cheese\", quantity=10, unit=\"grams\", physical_quality=\"\", color=\"orange\"),\n            FoodEntity(food=\"water\", quantity=2, unit=\"liters\", physical_quality=\"translucent\", color=\"\"),\n            FoodEntity(food=\"ice\", quantity=5, unit=\"militers\", physical_quality=\"cold\", color=\"white\")\n        ]\n    ).with_inputs(\"recipe\"),\n    dspy.Example(\n        recipe=\"Pasta carbonara, 250 grams of pasta 300 grams of pancetta, \\\n        150 grams pecorino romano, 150grams parmesan cheese, 3 egg yolks\", \n        entities=[\n            FoodEntity(food=\"pasta\", quantity=250, unit=\"grams\", physical_quality=\"dried\", color=\"yellow\"),\n            FoodEntity(food=\"egg yolk\", quantity=3, unit=\"\", physical_quality=\"\", color=\"orange\"),\n            FoodEntity(food=\"pancetta\", quantity=300, unit=\"grams\", physical_quality=\"pork\", color=\"\"),\n            FoodEntity(food=\"pecorino\", quantity=150, unit=\"grams\", physical_quality=\"goat chese\", color=\"yellow\"),\n            FoodEntity(food=\"parmesan\", quantity=150, unit=\"grams\", physical_quality=\"chese\", color=\"yellow\"),\n        ]\n    ).with_inputs(\"recipe\"),\n    dspy.Example(\n        recipe=\"American pancakes with 250g flour, 1 tsp baking powder, 1 gram salt, 10g sugar, 100ml fat milk\", \n        entities=[\n            FoodEntity(food=\"flour\", quantity=250, unit=\"grams\", physical_quality=\"\", color=\"white\"),\n            FoodEntity(food=\"baking powder\", quantity=1, unit=\"tsp\", physical_quality=\"\", color=\"white\"),\n            FoodEntity(food=\"salt\", quantity=1, unit=\"grams\", physical_quality=\"salty\", color=\"white\"),\n            FoodEntity(food=\"milk\", quantity=100, unit=\"mil\", physical_quality=\"fat\", color=\"white\"),\n        ]\n    ).with_inputs(\"recipe\")\n]\n```\n\nFor this you can use [dspy.Example](https://dspy-docs.vercel.app/docs/building-blocks/data)\n\n### Signatures\nThe next step is to create the `dspy.Signature` objects, where we need to specify an `InputField(...)` and `OutPutField(...)`. To recap what a `Signature` is:\n\n\u003CCallout type=\"info\" title=\"DSPy Signatures\">\nA **signature** is a declarative specification of the input/output behavior of a DSPy module. Signatures allow you to tell the LM what it needs to do, rather than specify how we should ask the LM to do it.\n\n‚Äî *DSPy Documentation*\n\u003C/Callout>\n\nBelow are the `Signatures` we will be using:\n\n```python\nclass RecipeToFoodContext(dspy.Signature):\n    \"\"\"You are a food AI assistant. Your task is to extract the entity, the value of the entity and the reasoning \n    for why the extracted value is the correct value. If you cannot extract the entity, add null\"\"\"\n    recipe: str = dspy.InputField()\n    context: FoodMetaData = dspy.OutputField()\n\nclass RecipeToFoodEntities(dspy.Signature):\n    \"\"\"You are a food AI assistant. Your task is to extract food-related metadata from recipes.\"\"\"\n    recipe: str = dspy.InputField()\n    entities: FoodEntities = dspy.OutputField()\n```\n\nNotice the modular and sleek nature of creating these compared to how it would look in other frameworks. Looking into the actual code for these you will see that these are wrappers for the `Pydantic` [Fields](https://docs.pydantic.dev/latest/concepts/fields/) object:\n\n```python\ndef InputField(**kwargs):\n    return pydantic.Field(**move_kwargs(**kwargs, __dspy_field_type=\"input\"))\n\ndef OutputField(**kwargs):\n    return pydantic.Field(**move_kwargs(**kwargs, __dspy_field_type=\"output\"))\n```\n\n### Modules\nThe next thing to do is select what `Modules` that we want to use. To recap what `Modules` are:\n\n\u003CCallout type=\"info\" title=\"DSPy Modules\">\nEach built-in module abstracts a prompting technique (like chain of thought or ReAct). Crucially, they are generalized to handle any `[DSPy Signature]`. Your init method declares the modules you will use. Your forward method expresses any computation you want to do with your modules\n\n‚Äî *DSPy Documentation*\n\u003C/Callout>\n\nThe `Modules` that we will be using are:\n1. `TypedPredictor`\n2. `TypedChainOfThought`\n\nThese are 2 `functional` modules that let us specify `types` via `Pydantic` schemas which are useful for `structured` data extraction. These can either be used with `dspy.Functional` or `dspy.Module`. However, before creating the actual modules, we will define 1 helper method to parse the `context` call:\n\n```python\ndef parse_context(food_context: FoodMetaData) -> str:\n    context_str = \"\"\n    for context in food_context:\n        context: FoodMetaData\n        context_str += f\"{context.entity}:\\n\" + context.model_dump_json(indent=4) + \"\\n\"\n    return context_str\n```\n\nThis is mainly to extract the resulting context `JSON` object as a string for the next step of the chain.\n\nMoving on to the actual `Modules` using `dspy.Module` we define it as:\n```python\nclass ExtractFoodEntities(dspy.Module):\n    def __init__(self, temperature: int = 0, seed: int = 123):\n        super().__init__()\n        self.temperature = temperature\n        self.seed = seed\n        self.extract_food_context = dspy.TypedPredictor(RecipeToFoodContext)\n        self.extract_food_context_cot = dspy.TypedChainOfThought(RecipeToFoodContext)\n        self.extract_food_entities = dspy.TypedPredictor(RecipeToFoodEntities)\n        \n    def forward(self, recipe: str) -> FoodEntities:\n        food_context = self.extract_food_context(recipe=recipe).context\n        parsed_context = parse_context(food_context.context)\n        food_entities = self.extract_food_entities(recipe=parsed_context)\n        return food_entities.entities\n```\n\nOr using `dspy.Functional` we define it as:\n```python\nfrom dspy.functional import FunctionalModule, predictor, cot\n\nclass ExtractFoodEntitiesV2(FunctionalModule):\n    def __init__(self, temperature: int = 0, seed: int = 123):\n        super().__init__()\n        self.temperature = temperature\n        self.seed = seed\n\n    @predictor\n    def extract_food_context(self, recipe: str) -> FoodMetaData:\n        \"\"\"You are a food AI assistant. Your task is to extract the entity, the value of the entity and the reasoning \n        for why the extracted value is the correct value. If you cannot extract the entity, add null\"\"\"\n        pass\n\n    @cot\n    def extract_food_context_cot(self, recipe: str) -> FoodMetaData:\n        \"\"\"You are a food AI assistant. Your task is to extract the entity, the value of the entity and the reasoning \n        for why the extracted value is the correct value. If you cannot extract the entity, add null\"\"\"\n        pass\n    \n    @predictor\n    def extract_food_entities(self, recipe: str) -> FoodEntities:\n        \"\"\"You are a food AI assistant. Your task is to extract food entities from a recipe.\"\"\"\n        pass\n        \n    def forward(self, recipe: str) -> FoodEntities:\n        food_context = self.extract_food_context(recipe=recipe)\n        parsed_context = parse_context(food_context.context)\n        food_entities = self.extract_food_entities(recipe=parsed_context)\n        return food_entities\n```\n\nUsing the `functional` API we can use some nifty decorator functions i.e. `@predictor` and `@cot`. Now when we have our `Module` we might want to test it on some example data. `DSPy` also allows you to specify a `dspy.Context` where you can choose what LLM to use:\n\n```python\nextract_food_entities = ExtractFoodEntities()\n\nwith dspy.context(lm=gpt4):\n    entities = extract_food_entities(recipe=\"Ten grams of orange dutch cheese,  \\\n    2 liters of water and 5 ml of ice\")\n    pprint(entities)\n```\n\nThis will result in the following `entities`:\n```python\nFoodEntities(\n    entities=[\n        FoodEntity(\n            food='orange dutch cheese',\n            quantity=10,\n            unit='grams',\n            physical_quality=None,\n            color='orange',\n        ),\n        FoodEntity(\n            food='water',\n            quantity=2000,\n            unit='milliliters',\n            physical_quality=None,\n            color='clear',\n        ),\n        FoodEntity(\n            food='ice',\n            quantity=5,\n            unit='milliliters',\n            physical_quality=None,\n            color='clear',\n        ),\n    ],\n)\n```\n\n### Optimize the program\nNow we have all the components we need to start `optimizing` our program. To recap:\n\n\u003CCallout type=\"info\" title=\"DSPy Optimizers\">\nA DSPy optimizer is an algorithm that can tune the parameters of a DSPy program (i.e., the prompts and/or the LM weights) to maximize the metrics you specify, like accuracy.\n\nDSPy programs consist of multiple calls to LMs, stacked together as `[DSPy modules]`. Each DSPy module has internal parameters of three kinds: (1) the LM weights, (2) the instructions, and (3) demonstrations of the input/output behavior.\n\nGiven a metric, DSPy can optimize all of these three with multi-stage optimization algorithms.\n\n‚Äî *DSPy Documentation*\n\u003C/Callout>\n\nFor the optimization, we will use the [BootstrapFewShot](https://dspy-docs.vercel.app/api/optimizers/BootstrapFewShot) and the metric below:\n\n```python\ndef validate_entities(example, pred, trace=None):\n    \"\"\"Check if both objects are equal\"\"\"\n    return example.entities == pred\n```\nI.e. we need an exact match for the objects\n\n\u003CCallout type=\"note\" title=\"Metric Considerations\">\n`BootstrapFewShot` is recommended if you have a few samples. A partial match might have been better to account for some randomness in the data extraction.\n\u003C/Callout>\n\nTo run the optimization step we use the `compile` method:\n\n```python\nfrom dspy.teleprompt import BootstrapFewShot\n\nteleprompter = BootstrapFewShot(metric=validate_entities)\ncompiled_ner = teleprompter.compile(ExtractFoodEntitiesV2(), trainset=trainset)\n```\n\nThe compiled programming is something we can store and load from disk as well for [later use](https://github.com/stanfordnlp/dspy/blob/main/dspy/primitives/module.py#L77).\n\nTo use the `compiled` program on our dataset we do:\n\n```python\npprint(compiled_ner(recipe=train_data))\n\nFoodEntities(\n    entities=[\n        FoodEntity(\n            food='pork belly',\n            quantity=2,\n            unit='lb',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='green onions',\n            quantity=2,\n            unit='items',\n            physical_quality='or 3 if small',\n            color='',\n        ),\n        FoodEntity(\n            food='fresh ginger',\n            quantity=1,\n            unit='inch',\n            physical_quality='chunk',\n            color='',\n        ),\n        FoodEntity(\n            food='garlic',\n            quantity=2,\n            unit='cloves',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='sake',\n            quantity=2,\n            unit='‚Öî cup',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='soy sauce',\n            quantity=2,\n            unit='‚Öî cup',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='mirin',\n            quantity=1,\n            unit='¬º cup',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='sugar',\n            quantity=1,\n            unit='¬Ω cup',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='water',\n            quantity=2,\n            unit='cups',\n            physical_quality='or a little more as needed',\n            color='',\n        ),\n    ],\n)\n```\n\nNot too bad after doing some code for a couple of hours üéâ. Finally to inspect the resulting prompt used by the program each `LM` has an `inspect_history` method:\n\n```python\ngpt4.inspect_history(n=1)\n```\n\nWhich outputs the prompt below:\n\n```shell\nYou are a food AI assistant. Your task is to extract food entities from a recipe.\n\n---\n\nFollow the following format.\n\nRecipe: ${recipe}\nExtract Food Entities: ${extract_food_entities}. Respond with a single JSON object. JSON Schema: {\"$defs\": {\"FoodEntity\": {\"properties\": {\"food\": {\"description\": \"This can be both liquid and solid food such as meat, vegetables, alcohol, etc\", \"title\": \"Food\", \"type\": \"string\"}, \"quantity\": {\"description\": \"The exact quantity or amount of the food that should be used in the recipe\", \"title\": \"Quantity\", \"type\": \"integer\"}, \"unit\": {\"description\": \"The unit being used e.g. grams, milliliters, pounds, etc\", \"title\": \"Unit\", \"type\": \"string\"}, \"physical_quality\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"description\": \"The characteristic of the ingredient\", \"title\": \"Physical Quality\"}, \"color\": {\"description\": \"The color of the food\", \"title\": \"Color\", \"type\": \"string\"}}, \"required\": [\"food\", \"quantity\", \"unit\", \"physical_quality\", \"color\"], \"title\": \"FoodEntity\", \"type\": \"object\"}}, \"properties\": {\"entities\": {\"items\": {\"$ref\": \"#/$defs/FoodEntity\"}, \"title\": \"Entities\", \"type\": \"array\"}}, \"required\": [\"entities\"], \"title\": \"FoodEntities\", \"type\": \"object\"}\n\n---\n\nRecipe:\npork belly:\n{\n    \"reasoning\": \"The recipe specifies using 2 lb of pork belly as the main ingredient for the chashu pork.\",\n    \"value\": \"2 lb\",\n    \"entity\": \"pork belly\"\n}\ngreen onions:\n{\n    \"reasoning\": \"The recipe calls for 2 green onions, or 3 if they are small, to be used in the cooking process.\",\n    \"value\": \"2 or 3\",\n    \"entity\": \"green onions\"\n}\nfresh ginger:\n{\n    \"reasoning\": \"A 1 inch chunk of fresh ginger is required, which will give around 4 - 6 slices for the recipe.\",\n    \"value\": \"1 in\",\n    \"entity\": \"fresh ginger\"\n}\ngarlic:\n{\n    \"reasoning\": \"2 cloves of garlic are needed as part of the ingredients.\",\n    \"value\": \"2 cloves\",\n    \"entity\": \"garlic\"\n}\nsake:\n{\n    \"reasoning\": \"‚Öî cup of sake is used in the cooking liquid for flavor.\",\n    \"value\": \"‚Öî cup\",\n    \"entity\": \"sake\"\n}\nsoy sauce:\n{\n    \"reasoning\": \"‚Öî cup of soy sauce is added to the cooking liquid, contributing to the dish's savory taste.\",\n    \"value\": \"‚Öî cup\",\n    \"entity\": \"soy sauce\"\n}\nmirin:\n{\n    \"reasoning\": \"¬º cup of mirin is included in the recipe for sweetness and depth of flavor.\",\n    \"value\": \"¬º cup\",\n    \"entity\": \"mirin\"\n}\nsugar:\n{\n    \"reasoning\": \"¬Ω cup of sugar is used to sweeten the cooking liquid.\",\n    \"value\": \"¬Ω cup\",\n    \"entity\": \"sugar\"\n}\nwater:\n{\n    \"reasoning\": \"2 cups of water (or a little more as needed) are required to create the cooking liquid for the pork.\",\n    \"value\": \"2 cups\",\n    \"entity\": \"water\"\n}\n\nExtract Food Entities: ```json\n{\n  \"entities\": [\n    {\n      \"food\": \"pork belly\",\n      \"quantity\": 2,\n      \"unit\": \"lb\",\n      \"physical_quality\": null,\n      \"color\": \"\"\n    },\n    {\n      \"food\": \"green onions\",\n      \"quantity\": 2,\n      \"unit\": \"items\",\n      \"physical_quality\": \"or 3 if small\",\n      \"color\": \"\"\n    },\n    {\n      \"food\": \"fresh ginger\",\n      \"quantity\": 1,\n      \"unit\": \"inch\",\n      \"physical_quality\": \"chunk\",\n      \"color\": \"\"\n    },\n    {\n      \"food\": \"garlic\",\n      \"quantity\": 2,\n      \"unit\": \"cloves\",\n      \"physical_quality\": null,\n      \"color\": \"\"\n    },\n    {\n      \"food\": \"sake\",\n      \"quantity\": 2,\n      \"unit\": \"‚Öî cup\",\n      \"physical_quality\": null,\n      \"color\": \"\"\n    },\n    {\n      \"food\": \"soy sauce\",\n      \"quantity\": 2,\n      \"unit\": \"‚Öî cup\",\n      \"physical_quality\": null,\n      \"color\": \"\"\n    },\n    {\n      \"food\": \"mirin\",\n      \"quantity\": 1,\n      \"unit\": \"¬º cup\",\n      \"physical_quality\": null,\n      \"color\": \"\"\n    },\n    {\n      \"food\": \"sugar\",\n      \"quantity\": 1,\n      \"unit\": \"¬Ω cup\",\n      \"physical_quality\": null,\n      \"color\": \"\"\n    },\n    {\n      \"food\": \"water\",\n      \"quantity\": 2,\n      \"unit\": \"cups\",\n      \"physical_quality\": \"or a little more as needed\",\n      \"color\": \"\"\n    }\n  ]\n}\n```\n```\n\n## Closing remarks\n\nThe aim for this post was for me to familiarize myself a bit more with `DSPy` that seems to be all the 'rave' lately. This is only an initial attempt to get a first understanding of what you can and cannot do. Hopefully, this will give you some insights on how you can get started with `DSPy` as well. \n\nHowever to summarize my first impressions:\n\n\u003CCallout type=\"success\" title=\"Pros\">\n- Easy to use and get started with ‚úÖ\n- Nice to not have to spend hours on prompt-engineering ‚úÖ  \n- Nice to treat this a a \"typical\" ML problem using `optimization` ‚úÖ\n\u003C/Callout>\n\n\u003CCallout type=\"warning\" title=\"Cons\">\n- Still evolving and not \"production ready\" yet ‚ùå\n- Needs better logging / tracing to make it easier to understand what is happening when you are debugging your programs ‚ùå\n\u003C/Callout>\n\nAll in all the approach of `programming` rather `prompting` really resonates with me and is inline with the current trends of [Compound AI systems](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/). Will be exciting to follow how this package evolves and matures over time. As prompting in its current state is not likely the future of building scalable, non-fragile and resilient systems using LLMs.","src/content/blog/ner-dspy.mdx","d01b7fe9ea722771","ner-dspy.mdx"]